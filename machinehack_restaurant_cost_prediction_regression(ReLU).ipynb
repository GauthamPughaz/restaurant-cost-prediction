{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    data_file = \"./processed_data.csv\"\n",
    "    df = pd.read_csv(data_file, index_col=0)    \n",
    "    columns = df.shape[1]\n",
    "    \n",
    "    X_train = (df.values[:10000, 0: columns-1]).T\n",
    "    Y_train = (df.values[:10000, -1]).T\n",
    "    X_dev = (df.values[10000: 12690, 0: columns-1]).T\n",
    "    Y_dev = (df.values[10000: 12690, -1]).T\n",
    "    X_test = (df.values[12690:, 0: columns-1]).T\n",
    "    \n",
    "    return X_train, Y_train.reshape((1, -1)), X_dev, Y_dev.reshape((1, -1)), X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholders(n_x, n_y):\n",
    "    X = tf.placeholder(shape=(n_x, None), name=\"X\", dtype=tf.float32)\n",
    "    Y = tf.placeholder(shape=(n_y, None), name=\"Y\", dtype=tf.float32)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    parameters = {}\n",
    "    W1 = tf.get_variable(shape=(50, 31), name=\"W1\", initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b1 = tf.get_variable(shape=(50, 1), name=\"b1\", initializer=tf.zeros_initializer())\n",
    "    W2 = tf.get_variable(shape=(100, 50), name=\"W2\", initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b2 = tf.get_variable(shape=(100, 1), name=\"b2\", initializer=tf.zeros_initializer())\n",
    "    W3 = tf.get_variable(shape=(1, 100), name=\"W3\", initializer=tf.contrib.layers.xavier_initializer(seed=1))\n",
    "    b3 = tf.get_variable(shape=(1, 1), name=\"b3\", initializer=tf.zeros_initializer())\n",
    "    parameters = {\n",
    "        \"W1\": W1,\n",
    "        \"W2\": W2,\n",
    "        \"W3\": W3,\n",
    "        \"b1\": b1,\n",
    "        \"b2\": b2,\n",
    "        \"b3\": b3\n",
    "    }\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    Z1 = tf.matmul(parameters[\"W1\"], X) + parameters[\"b1\"]\n",
    "    A1 = tf.nn.relu(Z1)\n",
    "    Z2 = tf.matmul(parameters[\"W2\"], A1) + parameters[\"b2\"]\n",
    "    A2 = tf.nn.relu(Z2)\n",
    "    Z3 = tf.matmul(parameters[\"W3\"], A2) + parameters[\"b3\"]\n",
    "    A3 = tf.nn.relu(Z3)\n",
    "    \n",
    "    return A3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(Z3, Y):\n",
    "    predictions = tf.transpose(Z3)\n",
    "    labels = tf.transpose(Y)\n",
    "    cost = tf.losses.mean_squared_error(labels=labels, predictions=predictions)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_mini_batches(X, Y, batch_size, seed):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X.T, Y.T)).shuffle(100, seed=seed).batch(batch_size)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_dev, Y_dev, X_test, num_epochs=20000, mini_batch_size=32, learning_rate=0.001):\n",
    "    n_x, m = X_train.shape\n",
    "    n_y, _ = Y_train.shape\n",
    "\n",
    "    X, Y = create_placeholders(n_x, n_y)\n",
    "    parameters = initialize_parameters()\n",
    "    A3 = forward_propagation(X, parameters)\n",
    "    cost = compute_cost(A3, Y)\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(init)\n",
    "        epoch_cost = 0\n",
    "        for epoch in range(num_epochs):\n",
    "            _, epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: Y_train})\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                print(\"Cost after {} epochs: {}\".format(epoch, epoch_cost))\n",
    "        \n",
    "        parameters = sess.run(parameters)\n",
    "        accuracy = 1 - tf.losses.mean_squared_error(predictions=A3, labels=Y_dev)\n",
    "        print(\"Accuracy on dev set: {}\".format(sess.run(accuracy, feed_dict={X: X_dev})))\n",
    "        \n",
    "        saved_path = saver.save(sess, \"./model/model.ckpt\")\n",
    "        print(\"Model saved in {}\".format(saved_path))\n",
    "        \n",
    "        predictions = sess.run(A3, feed_dict={X: X_test}) * 10000\n",
    "        \n",
    "    return predictions, parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0701 20:30:08.866951 4621616576 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0701 20:30:09.014090 4621616576 deprecation.py:323] From /anaconda3/envs/deep-learning/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 0 epochs: 0.0075616068206727505\n",
      "Cost after 100 epochs: 0.0017182441661134362\n",
      "Cost after 200 epochs: 0.0011704829521477222\n",
      "Cost after 300 epochs: 0.0009582120110280812\n",
      "Cost after 400 epochs: 0.0008270435500890017\n",
      "Cost after 500 epochs: 0.0007324058096855879\n",
      "Cost after 600 epochs: 0.000670223671477288\n",
      "Cost after 700 epochs: 0.0006214824388734996\n",
      "Cost after 800 epochs: 0.0005754194571636617\n",
      "Cost after 900 epochs: 0.00054593087406829\n",
      "Cost after 1000 epochs: 0.0005219418671913445\n",
      "Cost after 1100 epochs: 0.0005017521907575428\n",
      "Cost after 1200 epochs: 0.0004916427424177527\n",
      "Cost after 1300 epochs: 0.00047222705325111747\n",
      "Cost after 1400 epochs: 0.00046763542923144996\n",
      "Cost after 1500 epochs: 0.00047286361223086715\n",
      "Cost after 1600 epochs: 0.000443457713117823\n",
      "Cost after 1700 epochs: 0.0004420379118528217\n",
      "Cost after 1800 epochs: 0.00043257392826490104\n",
      "Cost after 1900 epochs: 0.0004177750670351088\n",
      "Cost after 2000 epochs: 0.00042199130984954536\n",
      "Cost after 2100 epochs: 0.00040500497561879456\n",
      "Cost after 2200 epochs: 0.0004096747434232384\n",
      "Cost after 2300 epochs: 0.0003986095543950796\n",
      "Cost after 2400 epochs: 0.0003972267732024193\n",
      "Cost after 2500 epochs: 0.0003893535758834332\n",
      "Cost after 2600 epochs: 0.00038079830119386315\n",
      "Cost after 2700 epochs: 0.0003833772207144648\n",
      "Cost after 2800 epochs: 0.00037399333086796105\n",
      "Cost after 2900 epochs: 0.00037046996294520795\n",
      "Cost after 3000 epochs: 0.00036914838710799813\n",
      "Cost after 3100 epochs: 0.000366486725397408\n",
      "Cost after 3200 epochs: 0.00037108303513377905\n",
      "Cost after 3300 epochs: 0.0003721735847648233\n",
      "Cost after 3400 epochs: 0.0003557566669769585\n",
      "Cost after 3500 epochs: 0.0003526805085130036\n",
      "Cost after 3600 epochs: 0.00035543585545383394\n",
      "Cost after 3700 epochs: 0.00035851498250849545\n",
      "Cost after 3800 epochs: 0.00035425295936875045\n",
      "Cost after 3900 epochs: 0.00034417558345012367\n",
      "Cost after 4000 epochs: 0.00035677533014677465\n",
      "Cost after 4100 epochs: 0.00036698137409985065\n",
      "Cost after 4200 epochs: 0.00034071889240294695\n",
      "Cost after 4300 epochs: 0.000342285493388772\n",
      "Cost after 4400 epochs: 0.0003347914607729763\n",
      "Cost after 4500 epochs: 0.00033884908771142364\n",
      "Cost after 4600 epochs: 0.00035558422678150237\n",
      "Cost after 4700 epochs: 0.00032915998599492013\n",
      "Cost after 4800 epochs: 0.00032771172118373215\n",
      "Cost after 4900 epochs: 0.00032620481215417385\n",
      "Cost after 5000 epochs: 0.0003348872996866703\n",
      "Cost after 5100 epochs: 0.0003257465723436326\n",
      "Cost after 5200 epochs: 0.00032640653080306947\n",
      "Cost after 5300 epochs: 0.00034147605765610933\n",
      "Cost after 5400 epochs: 0.00033341016387566924\n",
      "Cost after 5500 epochs: 0.00032153099891729653\n",
      "Cost after 5600 epochs: 0.0003244267136324197\n",
      "Cost after 5700 epochs: 0.00032292259857058525\n",
      "Cost after 5800 epochs: 0.0003176011086907238\n",
      "Cost after 5900 epochs: 0.0003172320721205324\n",
      "Cost after 6000 epochs: 0.0003133061691187322\n",
      "Cost after 6100 epochs: 0.00031940892222337425\n",
      "Cost after 6200 epochs: 0.00032597166136838496\n",
      "Cost after 6300 epochs: 0.00031000026501715183\n",
      "Cost after 6400 epochs: 0.0003205999964848161\n",
      "Cost after 6500 epochs: 0.0003093333507422358\n",
      "Cost after 6600 epochs: 0.0003149862168356776\n",
      "Cost after 6700 epochs: 0.00031261806725524366\n",
      "Cost after 6800 epochs: 0.00030449856421910226\n",
      "Cost after 6900 epochs: 0.0003321852709632367\n",
      "Cost after 7000 epochs: 0.00031176069751381874\n",
      "Cost after 7100 epochs: 0.00033096905099228024\n",
      "Cost after 7200 epochs: 0.00030133198015391827\n",
      "Cost after 7300 epochs: 0.0003011869266629219\n",
      "Cost after 7400 epochs: 0.0003131413832306862\n",
      "Cost after 7500 epochs: 0.0002979818091262132\n",
      "Cost after 7600 epochs: 0.00029972466290928423\n",
      "Cost after 7700 epochs: 0.0002973166119772941\n",
      "Cost after 7800 epochs: 0.00029564168653450906\n",
      "Cost after 7900 epochs: 0.00029641808941960335\n",
      "Cost after 8000 epochs: 0.00030800275271758437\n",
      "Cost after 8100 epochs: 0.00029429703135974705\n",
      "Cost after 8200 epochs: 0.0003090912941843271\n",
      "Cost after 8300 epochs: 0.0002923823776654899\n",
      "Cost after 8400 epochs: 0.00029261590680107474\n",
      "Cost after 8500 epochs: 0.00029945949790999293\n",
      "Cost after 8600 epochs: 0.00029046062263660133\n",
      "Cost after 8700 epochs: 0.000293478777166456\n",
      "Cost after 8800 epochs: 0.0002903833519667387\n",
      "Cost after 8900 epochs: 0.0002917938691098243\n",
      "Cost after 9000 epochs: 0.0002896049991250038\n",
      "Cost after 9100 epochs: 0.00028928686515428126\n",
      "Cost after 9200 epochs: 0.00029659990104846656\n",
      "Cost after 9300 epochs: 0.0002938366960734129\n",
      "Cost after 9400 epochs: 0.000286962982499972\n",
      "Cost after 9500 epochs: 0.0002923601714428514\n",
      "Cost after 9600 epochs: 0.00029149209149181843\n",
      "Cost after 9700 epochs: 0.0002844399423338473\n",
      "Cost after 9800 epochs: 0.0002832444733940065\n",
      "Cost after 9900 epochs: 0.00034924622741527855\n",
      "Cost after 10000 epochs: 0.00029859086498618126\n",
      "Cost after 10100 epochs: 0.00028486252995207906\n",
      "Cost after 10200 epochs: 0.0002915208169724792\n",
      "Cost after 10300 epochs: 0.00028485635994002223\n",
      "Cost after 10400 epochs: 0.0002822292735800147\n",
      "Cost after 10500 epochs: 0.0002859720552805811\n",
      "Cost after 10600 epochs: 0.0002905152796301991\n",
      "Cost after 10700 epochs: 0.00028787931660190225\n",
      "Cost after 10800 epochs: 0.0002787898120004684\n",
      "Cost after 10900 epochs: 0.00029533490305766463\n",
      "Cost after 11000 epochs: 0.00029152416391298175\n",
      "Cost after 11100 epochs: 0.0002817667555063963\n",
      "Cost after 11200 epochs: 0.0002836231142282486\n",
      "Cost after 11300 epochs: 0.0002780002250801772\n",
      "Cost after 11400 epochs: 0.00028170528821647167\n",
      "Cost after 11500 epochs: 0.0002753117587417364\n",
      "Cost after 11600 epochs: 0.00028222345281392336\n",
      "Cost after 11700 epochs: 0.00027865046286024153\n",
      "Cost after 11800 epochs: 0.00027437511016614735\n",
      "Cost after 11900 epochs: 0.000308608403429389\n",
      "Cost after 12000 epochs: 0.0002741609059739858\n",
      "Cost after 12100 epochs: 0.0002735138114076108\n",
      "Cost after 12200 epochs: 0.00028648963780142367\n",
      "Cost after 12300 epochs: 0.00027689553098753095\n",
      "Cost after 12400 epochs: 0.0002720510237850249\n",
      "Cost after 12500 epochs: 0.00027221327763982117\n",
      "Cost after 12600 epochs: 0.00027433823561295867\n",
      "Cost after 12700 epochs: 0.00027559249429032207\n",
      "Cost after 12800 epochs: 0.0002704155049286783\n",
      "Cost after 12900 epochs: 0.0003269775479566306\n",
      "Cost after 13000 epochs: 0.00027940774452872574\n",
      "Cost after 13100 epochs: 0.00029249736689962447\n",
      "Cost after 13200 epochs: 0.0002691697736736387\n",
      "Cost after 13300 epochs: 0.0002715878945309669\n",
      "Cost after 13400 epochs: 0.0002780423092190176\n",
      "Cost after 13500 epochs: 0.00027142855105921626\n",
      "Cost after 13600 epochs: 0.00027015572413802147\n",
      "Cost after 13700 epochs: 0.00029022389207966626\n",
      "Cost after 13800 epochs: 0.00027008031611330807\n",
      "Cost after 13900 epochs: 0.00027133297407999635\n",
      "Cost after 14000 epochs: 0.00028480953187681735\n",
      "Cost after 14100 epochs: 0.00027452249196358025\n",
      "Cost after 14200 epochs: 0.00026838143821805716\n",
      "Cost after 14300 epochs: 0.0002664092171471566\n",
      "Cost after 14400 epochs: 0.0002684024802874774\n",
      "Cost after 14500 epochs: 0.0002909317845478654\n",
      "Cost after 14600 epochs: 0.00026702487957663834\n",
      "Cost after 14700 epochs: 0.00026795390294864774\n",
      "Cost after 14800 epochs: 0.0002967995242215693\n",
      "Cost after 14900 epochs: 0.00026607292238622904\n",
      "Cost after 15000 epochs: 0.000303255656035617\n",
      "Cost after 15100 epochs: 0.00027539304574020207\n",
      "Cost after 15200 epochs: 0.0002672943228390068\n",
      "Cost after 15300 epochs: 0.00026728209923021495\n",
      "Cost after 15400 epochs: 0.00028317817486822605\n",
      "Cost after 15500 epochs: 0.000268190517090261\n",
      "Cost after 15600 epochs: 0.00027870500343851745\n",
      "Cost after 15700 epochs: 0.0002736249298322946\n",
      "Cost after 15800 epochs: 0.0002925220469478518\n",
      "Cost after 15900 epochs: 0.00026473120669834316\n",
      "Cost after 16000 epochs: 0.00026327077648602426\n",
      "Cost after 16100 epochs: 0.0002722684002947062\n",
      "Cost after 16200 epochs: 0.00026392139261588454\n",
      "Cost after 16300 epochs: 0.0002686398511286825\n",
      "Cost after 16400 epochs: 0.0002709031105041504\n",
      "Cost after 16500 epochs: 0.00026736428844742477\n",
      "Cost after 16600 epochs: 0.0002673636772669852\n",
      "Cost after 16700 epochs: 0.0002627091307658702\n",
      "Cost after 16800 epochs: 0.00027566327480599284\n",
      "Cost after 16900 epochs: 0.000267048308160156\n",
      "Cost after 17000 epochs: 0.0002649288217071444\n",
      "Cost after 17100 epochs: 0.00025900962646119297\n",
      "Cost after 17200 epochs: 0.0002635974087752402\n",
      "Cost after 17300 epochs: 0.0002751686261035502\n",
      "Cost after 17400 epochs: 0.00026203523157164454\n",
      "Cost after 17500 epochs: 0.0002595252590253949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after 17600 epochs: 0.0003307885199319571\n",
      "Cost after 17700 epochs: 0.0002602778549771756\n",
      "Cost after 17800 epochs: 0.00025767445913515985\n",
      "Cost after 17900 epochs: 0.00029383646324276924\n",
      "Cost after 18000 epochs: 0.0002626281639095396\n",
      "Cost after 18100 epochs: 0.00031044473871588707\n",
      "Cost after 18200 epochs: 0.0002662832266651094\n",
      "Cost after 18300 epochs: 0.000255337858106941\n",
      "Cost after 18400 epochs: 0.0002643192419782281\n",
      "Cost after 18500 epochs: 0.00026181346038356423\n",
      "Cost after 18600 epochs: 0.00025526454555802047\n",
      "Cost after 18700 epochs: 0.00027145861531607807\n",
      "Cost after 18800 epochs: 0.0002794539323076606\n",
      "Cost after 18900 epochs: 0.0002562327135819942\n",
      "Cost after 19000 epochs: 0.0002849460288416594\n",
      "Cost after 19100 epochs: 0.00025313725927844644\n",
      "Cost after 19200 epochs: 0.0002575516700744629\n",
      "Cost after 19300 epochs: 0.0002567005867604166\n",
      "Cost after 19400 epochs: 0.00027547136414796114\n",
      "Cost after 19500 epochs: 0.00026542844716459513\n",
      "Cost after 19600 epochs: 0.0002519125700928271\n",
      "Cost after 19700 epochs: 0.00025174461188726127\n",
      "Cost after 19800 epochs: 0.00029637027182616293\n",
      "Cost after 19900 epochs: 0.0002759193885140121\n",
      "Accuracy on dev set: 0.9964907169342041\n",
      "Model saved in ./model.ckpt\n"
     ]
    }
   ],
   "source": [
    "predictions, parameters = model(*load_dataset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\"COST\": np.squeeze(predictions)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"predicted_costs.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep-learning] *",
   "language": "python",
   "name": "conda-env-deep-learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
